parse_source <- function(x,
                         codeRegexes = c(code = "\\[\\[([a-zA-Z0-9._-]+)\\]\\]"),
                         idRegexes = c(caseId = "\\[\\[cid=([a-zA-Z0-9._-]+)\\]\\]",
                                       stanzaId = "\\[\\[sid=([a-zA-Z0-9._-]+)\\]\\]"),
                         autoGenerateId = c('stanzaId'),
                         sectionRegexes = c(paragraphs = "---paragraph-break---",
                                            secondary = "---<>---"),
                         delimiterRegEx = "^---$",
                         ignoreOddDelimiters=FALSE,
                         silent=FALSE) {

  ### First process YAML fragments and remove them
  yamlFragments <-
    delete_yaml_fragments(text=x,
                          delimiterRegEx=delimiterRegEx,
                          ignoreOddDelimiters=ignoreOddDelimiters);
  x <-
    delete_yaml_fragments(text=x,
                          delimiterRegEx=delimiterRegEx,
                          ignoreOddDelimiters=ignoreOddDelimiters);

  ### Create dataframe for parsing
  sourceDf <- data.frame(utterances_raw = x);

  ### Identify sections
  if (!is.null(sectionRegexes) && length(sectionRegexes) > 0) {
    for (sectionRegex in names(sectionRegexes)) {
      ### Store whether each utterance matches
      sourceDf[, glue::glue("{sectionRegex}_match")] <-
        grepl(sectionRegexes[sectionRegex], x);
      ### Set incremental counter for each match
      sourceDf[, glue::glue("{sectionRegex}_counter")] <-
        purrr::accumulate(sourceDf[, glue::glue("{sectionRegex}_match")],
                          `+`);
    }
  }

  ### Process identifiers
  if (!is.null(idRegexes) && length(idRegexes) > 0) {
    for (idRegex in names(idRegexes)) {

      ### Get a list of matches
      ids <-
        regmatches(x,
                   gregexpr(idRegexes[idRegex], x));

      ### Check whether there are multiple matches
      multipleIds <-
        which(unlist(lapply(ids, length))>1);
      if (length(multipleIds) > 0) {
        warning(glue::glue("Multiple identifiers matching '{idRegex}' found in the following utterances:\n",
                       paste0(x[multipleSids],
                              collapse="\n"),
                       "\n\nOnly using the first identifier for each utterance, removing and ignoring the rest!"));
        ids <-
          lapply(ids, head, 1);
      }

      ### Clean identifiers (i.e. only retain identifier content itself)
      ids <-
        lapply(ids, gsub, pattern=idRegexes[idRegex], replacement="\\1");

      ### Set "no_id" for utterances without id
      ids <-
        ifelse(unlist(lapply(ids,
                             length)),
               ids,
               "no_id");

      ### Convert from a list to a vector
      ids <- unlist(ids);

      ### Generate identifiers for ids without identifier
      if (idRegex %in% autoGenerateId) {
        ids[ids=="no_id"] <-
          paste0("autogenerated_id_",
                 1:(sum(ids=="no_id")));
      }

      ### Store identifiers in sourceDf
      sourceDf[, idRegex] <-
        ids;
    }
  }

  ### Delete identifiers and store clean version in sourceDf
  x <-
    gsub(paste0(idRegexes, collapse="|"),
         "",
         x);
  sourceDf$utterances_without_identifiers <- x;

  codings <- list();
  ### Process codes
  if (!is.null(codeRegexes) && length(codeRegexes) > 0) {
    for (codeRegex in names(codeRegexes)) {

      ### Find matches
      matches <-
        regmatches(x,
                   gregexpr(codeRegexes[codeRegex], x));

      ### Retain only the parenthesized expression
      cleanedMatches <-
        lapply(matches, gsub, pattern=codeRegexes[codeRegex], replacement="\\1");

      ### Get a complete list of all used codes
      codings[[codeRegex]] <-
        sort(unique(unlist(cleanedMatches)));

      ### Get presence of codes in utterances
      occurrences <-
        lapply(cleanedMatches,
               `%in%`,
               x=codings[[codeRegex]]);

      ### Convert from logical to numeric
      occurrenceCounts <-
        lapply(occurrences, as.numeric);

      ### Add the codes as names
      namedOccurrences <-
        lapply(occurrenceCounts,
               `names<-`,
               value <- codings[[codeRegex]]);

      ### Convert from a vector to a list
      namedOccurrences <-
        lapply(namedOccurrences,
               as.list);

      ### Convert the lists to dataframes
      sourceDf <-
        cbind(sourceDf,
              do.call(rbind, namedOccurrences));

      ### Delete codes from utterances
      x <-
        gsub(paste0(codeRegexes[codeRegex]),
             "",
             x);

    }
  }

  ### Trim spaces from front and back and store clean utterances
  sourceDf$utterances_clean <-
    trimws(x);

  # ### Remove paragraph breaks from the list of
  # ### utterances and from the other lists
  # utterances <- x[lines=="Utterance"];
  # paragraphs <- paragraphs[lines=="Utterance"];

  return(structure(list(sourceDf = sourceDf,
                        codings = codings,
                        yamlFragments = yamlFragments),
                   class="rockParsedSource"));

}

x <- readLines("B:/Data/research/qualitative-quantitative interfacing/Qualitative rENA/arena/sylvias-test.rock",
               encoding="UTF-8");

y <- parse_source(x);
